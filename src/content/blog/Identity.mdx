---
title: "Connecting the dots: Architecting Identity-based Knowledge Graphs for activating Financial Journeys"
date: "2025-09-01"
description: "Explores how enterprise knowledge graphs (Neo4j) use identity as a connective layer to unify customer data, enabling omni-channel analytics, AI-driven personalization, and regulatory reporting."
---

{/* Placeholder for Hero Image */}


### Introduction: Modern Marketing and Fragmented Data

Modern marketing has shifted from broad-based campaigns to highly personalized customer journeys driven by individual behavior. Customers now expect companies to reach out to them “at the time *they* need, on the channel *they* like, with the content *they* want”. Delivering on these expectations requires, in addition to Martech platforms, integrating data across many touchpoints. Unfortunately, customer data often remains siloed across products, channels, and systems. The resulting data fragmentation presents a huge hurdle for unified analytics and personalization.

Just to illustrate the point of fragmentation, take a typical customer journey - even though the basic journey funnel looks simple and sequential, the actual flow is often non-sequential, intricate and multi-dimensional, presenting numerous points where leads can disengage and can re-establish engagement. This complexity is further compounded by the existence of interaction events happening across various product lines, marketing channels, contact channels and therefore captured in siloed systems. While the abundance of customer and interaction data generated can offer significant insights for strategic decision-making, the siloed and fragmented nature prevents us from effectively modelling this data to derive meaningful conclusions.

<img src="/images/blog/identity/funnel.jpg" alt="Customer Journey Graph Placeholder" />
<span style={{ fontSize: "0.85em", fontStyle: "italic" }}>
Figure 1: Basic customer journey funnel(left). The actual journey often can be non-sequential and complex as depicted on right
</span>

Marketing teams therefore need to build a **unified customer data layer** anchored by a consistent enterprise identity. In this model, all customer identifiers, attributes, and interactions can be consolidated and connected to a single customer entity. This approach enables consolidation of disparate data into one coherent identity graph and helps us connect the dots in data. 

Graph database technology is a natural fit for this design: by treating customers, events, and identifiers as interconnected nodes, a graph provides flexibility and expressive power that static tables do not. The graph database solution lets us associate multi-dimensional data such as customer email, phone, physical address, product and account relationships, as well as interaction events like support calls, chats, emails and clickstream views, cutting across layers of multiple products and their siloed systems. In doing so, it enables us to visualize customer behavior better and identify and persist new associations that existing data systems find difficult to capture today.
<img src="/images/blog/identity/identity-hero.jpg" alt="Hero Image Placeholder" />



By connecting fragmented data into cohesive journey maps, these graphs will help us unlock household insights, optimize lifecycle engagement, drive acquisition and re-engagement strategies and deepen customer relationships at scale. Let's look at some use cases where such a data structure can help with marketing.

### Marketing Use cases leveraging Identity Graphs

A well-designed Identity graph, associating both profiles and multi-channel events to an identity addresses several next-gen marketing use cases:

The unified customer graph directly supports core marketing analytics. One major use case is **multi-touch attribution**. By tracing a customer’s path through multiple channels, the graph helps attribute conversion credit across steps. For example, if a user saw an ad, clicked an email, and later converted on the website, the graph can link all these events to the same customer node. In a traditional attribution approach, since one can't see the sequence of previous touchpoints, the last touchpoint just before conversion (in the above example, the website) is attributed 100% of the credit. This is often called *last-touch attribution*. However, with the unified customer graph companies can understand the sequence and significance of events/channels that lead to conversion and attribute it fractionally. This enables accurate calculation of metrics like cost-per-acquisition (CPA) by understanding exactly which channels and journeys led to conversions, which in turn determines the marketing spend and profitability across channels in the future. 

<img src="/images/blog/identity/multitouch.png" alt="multi touch placeholder" />
<span style={{ fontSize: "0.85em", fontStyle: "italic" }}>
Figure 3: Multi-touch use case process
</span>

Another use case is **householding and behavior-based segmentation**. The graph can identify when multiple customer records share attributes (such as an address or phone number), implying they belong to the same household or group. Shared attribute nodes cause those customer nodes to become connected, and an explicit “household” edge can further link them as a group. Likewise, similar audiences can be discovered by clustering customers with common behaviors or attributes. These segments then allow marketers to tailor content to groups (or households) with shared characteristics.

<img src="/images/blog/identity/household.png" alt="household placeholder" />
<span style={{ fontSize: "0.85em", fontStyle: "italic" }}>
Figure 4: Household use case process
</span>

Few other use cases worth mentioning: 
- **Enable new re-engagement strategies**: Often customers dis-engage and * fall-out* from the conversion funnel. The unified customer data layer / graph can help understand what led to the dis-engagement and help determine and activate re-engagement strategies.

- **Identify known individuals even with partial information**: Broad-market prospects with limited / missing / incorrectly recorded contact information can be matched to existing customer profiles using partial attribute matches  - helping us find the best way to reach out to them and re-engage

- **Advanced personalization**: By leveraging ML feature stores and signals derived from events associated in graphs, very advanced offer propensity models can be put in place to improve profitability

- **Next-Best Action** : Determine next best action, in marketing & servicing processes, based on omni-channel events, associated in the graph

- **Data source to Martech platforms** : A well-established identity graph can be an incredible foundational data structure for platform like CDPs(Customer Data Platforms) as well as to send data to *walled-gardens* such as Google / Facebook for look-alike modeling and marketing segmentation / activation. 

Considering these use cases are not just important for understanding the value of the data layer, but also for determining the design and even the implementation of the graph.

### Why Graph Database is the right solution for the Unified Customer Data Layer

Graph databases offer several key benefits for a unified customer data layer. They allow a **more natural representation of real-world relationships** and behaviors. For example, a graph can directly model that a customer (node) has an email, a phone number, and a sequence of website visits (edges), whereas a relational schema would require complex joins. The graph schema can evolve with new data and use cases without major rework: nodes and relationships can be added as business questions change.

Graphs also facilitate **relationship inference**. In a fragmented data environment, many data points are initially unconnected. A graph database makes it easy to derive linkages through traversal or analytics. For instance, machine-learning or fuzzy matching algorithms can create edges between events and a customer when the associations are uncertain. Pre-known query patterns (like customer journey analysis) can be optimized into graph traversals to boost performance.

Crucially, graph design can improve privacy regulation compliance which is paramount for marketing personalization use cases. By modeling each person’s PII (Personally Identifiable Information) on a unique node, the database inherently **centralizes sensitive data**. This means each individual’s personal data is stored only once, simplifying updates or deletions under privacy regulations. In fact, identity resolution – the process of linking identifiers to a single person – is now “essential for compliance” with laws like GDPR and CCPA. A well-designed graph that unifies customer identifiers thus aligns naturally with modern data governance demands.

By contrast, relational designs impose rigid schemas and require complex joins, which degrade performance and make it harder to capture sequential journeys or infer hidden linkages. Additionally, in a relational warehouse, implementing relationship inference through machine learning requires cumbersome ETL and denormalization. 



### How to think of Design & Implementation

Deciding to proceed with a graph solution for the unified customer data layer is only the first step. Careful planning is needed to ensure design is future-proof and implementation is performant.

#### Data Model

Your use cases need to guide graph modeling and ingestion. At the core of the graph is a **ground-truth customer identity**. A central customer ID node is linked to deterministic identifiers (such as primary account IDs or verified emails) with high confidence. This ground-truth linkage ensures the graph can reliably attribute data to the correct individual across systems. Beyond those deterministic links, the graph can also help uncover probabilistic associations (for example, inferred connections or soft relationships) using Graph Data Science packages.

Every element – nodes, properties, and relationships – needs  to be defined by the business questions to be answered. Decide whether a feature should be a node, a node property, or a relationship by asking: “*What question must this model answer?* ”. 

Graph data models can support an evolving graph schema without drastic changes over time. As new use cases emerge, the model could be extended (for example, by adding new node types or relationships) without disrupting existing structures.

Privacy and retention considerations are better baked in from the start. PII and sensitive attributes can be modeled as easily mutable graph elements, enabling compliance with data retention policies. In practice, this means a person’s identifying nodes (email, phone, etc.) can be updated or removed in one place when required.

##### Conceptual Graph Model

An example conceptual customer graph (Figure 3) is below. The customer node sits at the center of a web of information. Personal identifiers (email, phone, address) are each represented by nodes linked to the customer node. Interaction events (such as website visits or applications) also connect to the customer node, preserving temporal order. The graph is directed, so edges flow in time sequence, and weighted, so more recent or frequent interactions carry greater significance.

<img src="/images/blog/identity/graph.png" alt="Customer Graph Placeholder" />
<span style={{ fontSize: "0.85em", fontStyle: "italic" }}>
Figure 3: A conceptual customer identity graph. The central customer node is connected to personal identifiers (PII), events, and attributes. Directed, weighted edges encode the sequence and importance of each customer touchpoint.
</span>


This structure can support the key use cases discussed earlier. For example, for multi-touch attribution, an event node (e.g. a loan application) will connect through edges to the customer, their phone and email nodes, and any related web or ad interaction nodes. Those edges together trace the full journey that led to that event. For householding, customers who share an attribute (like the same address) naturally connect to the same address node. The graph can even create a synthetic “household” edge directly between customer nodes to explicitly represent that relationship. Thus, the model inherently captures both individual journeys and group affinities, making them easy to query.

#### Data Pipeline

Data pipeline design can vary significantly on whether implementation is on cloud vs on-prem and the graph technology used. A cloud implementation might leverage PySpark/EMR for ETL, sourcing base data from Snowflake(as shown below) into Neo4j, which was our choice of Graph database technology. Neo4J GDS(Graph Data Science) capabilities will need to be leveraged to determine synthetic groupings(such as family-name based households) or linkages (probabilistic linkage of a web event to an identity)

In our case, the data pipeline integrates both cloud and on-premise sources into the graph. All raw data first flows into a data warehouse (Snowflake) where it is cleaned and transformed. A Spark-based ETL then loads and updates the graph: using PySpark and Neo4j’s parallel Spark connector, data is ingested into Neo4j in bulk. An AWS Step Functions job orchestrates this workflow: it launches a transient EMR cluster, runs the PySpark ingestion job on that cluster, waits for completion, and then tears down the cluster to save costs. In this way, large volumes of clickstream, transaction, and CRM data can be processed in parallel.

<img src="/images/blog/identity/etl.png" alt="ETL Placeholder" />
<span style={{ fontSize: "0.85em", fontStyle: "italic" }}>
Figure 4: Data pipeline for the customer identity graph. Multiple data sources are cleaned and modeled, then ingested via a Spark-based ETL into Neo4j. The graph is queried by BI tools and also exported for downstream use.
</span>

The Neo4j database can be hosted on EC2 instances (if on cloud - for example, 256 GB RAM, 8 cores) or on-prem instances (depending on your deployment environment) to handle query and ingestion loads. Once the graph is built, data customers access it in multiple ways. High-level analyses and dashboards use tools like NeoDash and Tableau, which issue Cypher queries against Neo4j. In parallel, detailed graph features can be exported (via PySpark) back into the warehouse or data lakes for model training and deeper analytics. In this hybrid setup, the graph serves both as an analytical store and as an operational data source for machine learning pipelines.

#### Performance Optimizations & Best Practices

As we ran our system, several tactical optimizations proved important for performance and manageability:

First, ultra-fine-grained data (e.g. clickstream logs with every page view) were **aggregated** to a higher-level summary. By rolling up these detailed events into coarser nodes, storage was saved while retaining actionable information. Second, the team pre-identified major customer segments or cohorts. Segment identifiers were **precomputed** and **attached as relationship properties** in the graph, so that queries could filter directly on those segments. This reduces the query scope and greatly improves traversal speed.

Identifier matching was another focus area. Customer names and attributes often have variations or typos. To support fuzzy matching, these values were embedded as **vector features** (using word embedding models) rather than relying on exact string matches. This allows the system to link records based on similarity with confidence scores, improving match rates.

Finally, thorough **data cleaning** before loading proved valuable. Generic or placeholder emails/phone numbers were filtered out, and duplicate records were merged. Removing these noisy, dense data points prevented extremely high-degree nodes and unnecessary graph traversals. In practice, this meant simpler, faster queries: each graph traversal had fewer dead-ends and less duplication to sift through.

Collectively, these efforts streamlined the graph performance significantly.

### Key Takeaways

**Start with use cases:** Defining clear Marketing use cases (attribution, householding, segmentation) early on immensely helps with every subsequent decision. Use cases drove which data to include and how to model relationships, how performant they should be etc., resulting in a focused and robust graph design.

**Plan for scale:** Estimating compute and storage needs for Graph solution is iterative especially, if you are provisioning a self-managed graph cluster (like we did) and will require conservative planning and testing under load.

**Expect integration challenges:** In a hybrid-cloud enterprise environment, connecting legacy systems, data warehouses, and new graph infrastructure introduce security and operational complexities. Regular collaboration with IT and data platform teams is essential to address these challenges early.

**Simplify graph consumption:** Graphs and Cypher have a learning curve. We created simplified views and templates for common queries so that less-technical analysts could leverage the data without needing deep Cypher knowledge.

**May need other Martech platforms for real-time use cases:** What we discussed here is just around data capabilities. To leverage these data capabilities fully for operational use cases, and create effective, interactive real-time customer journeys, other platforms such as personalization engines, CDPs etc. may be needed in your environment. Partner closely with your Martech organization to ensure the data environment has adequate connectivity and resiliency.

### Conclusion

For organizations wrestling with fragmented customer data and stringent privacy rules, a graph-based unified customer data layer enables more accurate attribution, richer personalization, and more maintainable privacy controls than traditional relational approaches for edge-heavy marketing problems. It can serve as the heart of the marketing data platform, unifying identities across the enterprise and empowering smarter marketing decisions. By anchoring the model on an enterprise identity, isolating PII, and designing the pipeline for incremental updates and scale, you can turn fragmented first-party data into an actionable foundation for modern marketing.